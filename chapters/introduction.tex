%!TEX root = ../lecture_notes.tex


\section{Introduction}
\label{cap:intro}


These lecture notes accompany the course Mathematics for Machine Learning, taught jointly with Dr Eleonora Giunchiglia, for the MSc in Artificial Intelligence Applications and Innovation at Imperial College London. The aim of the course is to develop a rigorous mathematical foundation for modern machine learning, bridging core ideas in linear algebra, calculus,  optimisation, probability, and statistics with the practical methodologies used in contemporary ML systems. While many ML courses emphasise models and applications, our focus here is on the underlying mathematical principles that make these methods work, that explain their limitations, and that guide their correct and informed use.

This first version of the notes currently covers only the second half of the course, that is Calculus, Probability and Statistics. The contents of the notes are based on the set of fantastic textbooks presented in the references, which I have tried my best to synthesise to align with this particular course. All the plots and simulations have been produced by Mr Camilo Carvajal Reyes, PhD student in Mathematics at Imperial and teaching assistant of the course. I am infinitely grateful for his help, support and constructive feedback during the realisation of the course.

These notes will remain a work in progress: material will be expanded, reorganised, and refined as the course develops and as new demonstrations and examples are incorporated. In particular, I aim to include the first half of the course (Linear Algebra, Geometry and Calculus) in the second iteration of the course.

The latest version of this document, along with accompanying demonstrations and computational notebooks, can be found in the course GitHub repository. Students are encouraged to consult it regularly, as it will be updated throughout the term.



\bigskip
\begin{flushright}
  Felipe Tobar\par
  1 December 2025\par
  London, UK
\end{flushright}

